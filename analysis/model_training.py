"""
–û–±—É—á–µ–Ω–∏–µ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
–≠—Ç–∞–ø 2: Model Training & Comparison
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import json
import joblib

from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')


class BoardGameModelTrainer:
    def __init__(self, data_path='data/processed/games_clean.csv'):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π"""
        self.data_path = data_path
        self.df = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        self.models = {}
        self.results = {}
        self.scaler = StandardScaler()
        self.mlb_categories = MultiLabelBinarizer()
        self.mlb_mechanics = MultiLabelBinarizer()

    def load_data(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        print("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        self.df = pd.read_csv(self.data_path)
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {self.df.shape}")
        return self.df

    def prepare_features(self):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è"""
        print("\n" + "="*80)
        print("üîß –ü–û–î–ì–û–¢–û–í–ö–ê –ü–†–ò–ó–ù–ê–ö–û–í")
        print("="*80)

        # –¶–µ–ª–µ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫
        target = 'average'

        # –ë–∞–∑–æ–≤—ã–µ —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        numeric_features = [
            'yearpublished',
            'minplayers',
            'maxplayers',
            'playingtime',
            'minplaytime',
            'maxplaytime',
            'minage',
            'averageweight',
            'usersrated',
            'num_categories',
            'num_mechanics'
        ]

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
        numeric_features = [f for f in numeric_features if f in self.df.columns]

        print(f"\nüìã –ë–∞–∑–æ–≤—ã–µ —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ({len(numeric_features)}):")
        for f in numeric_features:
            print(f"   ‚Ä¢ {f}")

        # –°–æ–∑–¥–∞–Ω–∏–µ DataFrame —Å —á–∏—Å–ª–æ–≤—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        X_numeric = self.df[numeric_features].copy()

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π (One-Hot Encoding –¥–ª—è —Ç–æ–ø-20 –∫–∞—Ç–µ–≥–æ—Ä–∏–π)
        print("\nüè∑Ô∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π...")

        category_lists = []
        for cat_str in self.df['boardgamecategory'].fillna('[]'):
            try:
                cats = eval(cat_str)
                category_lists.append(cats if isinstance(cats, list) else [])
            except:
                category_lists.append([])

        # –ü–æ–¥—Å—á–µ—Ç —á–∞—Å—Ç–æ—Ç—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        all_cats = [cat for cats in category_lists for cat in cats]
        top_categories = pd.Series(all_cats).value_counts().head(20).index.tolist()

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ —Ç–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        filtered_categories = [[cat for cat in cats if cat in top_categories]
                               for cats in category_lists]

        # MultiLabelBinarizer –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        categories_encoded = self.mlb_categories.fit_transform(filtered_categories)
        categories_df = pd.DataFrame(
            categories_encoded,
            columns=[f'cat_{cat}' for cat in self.mlb_categories.classes_]
        )

        print(f"   –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–ø-{len(top_categories)} –∫–∞—Ç–µ–≥–æ—Ä–∏–π")

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–µ—Ö–∞–Ω–∏–∫ (—Ç–æ–ø-15)
        print("üéÆ –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–µ—Ö–∞–Ω–∏–∫...")

        mechanic_lists = []
        for mech_str in self.df['boardgamemechanic'].fillna('[]'):
            try:
                mechs = eval(mech_str)
                mechanic_lists.append(mechs if isinstance(mechs, list) else [])
            except:
                mechanic_lists.append([])

        all_mechs = [mech for mechs in mechanic_lists for mech in mechs]
        top_mechanics = pd.Series(all_mechs).value_counts().head(15).index.tolist()

        filtered_mechanics = [[mech for mech in mechs if mech in top_mechanics]
                              for mechs in mechanic_lists]

        mechanics_encoded = self.mlb_mechanics.fit_transform(filtered_mechanics)
        mechanics_df = pd.DataFrame(
            mechanics_encoded,
            columns=[f'mech_{mech}' for mech in self.mlb_mechanics.classes_]
        )

        print(f"   –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–ø-{len(top_mechanics)} –º–µ—Ö–∞–Ω–∏–∫")

        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        X = pd.concat([X_numeric, categories_df, mechanics_df], axis=1)
        y = self.df[target]

        print(f"\n‚úÖ –ò—Ç–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {X.shape[1]}")
        print(f"   ‚Ä¢ –ß–∏—Å–ª–æ–≤—ã—Ö: {len(numeric_features)}")
        print(f"   ‚Ä¢ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏: {categories_df.shape[1]}")
        print(f"   ‚Ä¢ –ú–µ—Ö–∞–Ω–∏–∫–∏: {mechanics_df.shape[1]}")

        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test (80/20)
        print(f"\nüìä –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö (80% train / 20% test)...")
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        print(f"   Train: {self.X_train.shape[0]} –æ–±—Ä–∞–∑—Ü–æ–≤")
        print(f"   Test: {self.X_test.shape[0]} –æ–±—Ä–∞–∑—Ü–æ–≤")

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        print("\nüîÑ –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        self.X_train_scaled = self.scaler.fit_transform(self.X_train)
        self.X_test_scaled = self.scaler.transform(self.X_test)

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ preprocessors
        Path('models').mkdir(parents=True, exist_ok=True)
        joblib.dump(self.scaler, 'models/scaler.pkl')
        joblib.dump({
            'categories': self.mlb_categories,
            'mechanics': self.mlb_mechanics,
            'feature_names': X.columns.tolist(),
            'numeric_features': numeric_features,
            'top_categories': top_categories,
            'top_mechanics': top_mechanics
        }, 'models/encoders.pkl')

        print("üíæ Preprocessors —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: models/scaler.pkl, models/encoders.pkl")

        return self.X_train_scaled, self.X_test_scaled, self.y_train, self.y_test

    def train_linear_model(self):
        """–û–±—É—á–µ–Ω–∏–µ –ª–∏–Ω–µ–π–Ω–æ–π –º–æ–¥–µ–ª–∏ (Ridge Regression)"""
        print("\n" + "="*80)
        print("üìà –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò 1: Ridge Regression (–õ–∏–Ω–µ–π–Ω–∞—è)")
        print("="*80)

        # –ü–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        print("\nüîç –ü–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å GridSearchCV...")

        param_grid = {
            'alpha': [0.1, 1.0, 10.0, 100.0]
        }

        ridge = Ridge(random_state=42)
        grid_search = GridSearchCV(
            ridge, param_grid, cv=5,
            scoring='neg_mean_absolute_error',
            n_jobs=-1, verbose=1
        )

        grid_search.fit(self.X_train_scaled, self.y_train)

        print(f"\n‚úÖ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {grid_search.best_params_}")
        print(f"   –õ—É—á—à–∏–π score (MAE): {-grid_search.best_score_:.4f}")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        self.models['ridge'] = grid_search.best_estimator_

        return self.models['ridge']

    def train_ensemble_model(self):
        """–û–±—É—á–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª–µ–≤–æ–π –º–æ–¥–µ–ª–∏ (Random Forest)"""
        print("\n" + "="*80)
        print("üå≤ –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò 2: Random Forest (–ù–µ–ª–∏–Ω–µ–π–Ω–∞—è)")
        print("="*80)

        # –ü–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        print("\nüîç –ü–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å GridSearchCV...")

        param_grid = {
            'n_estimators': [100, 200],
            'max_depth': [10, 20, None],
            'min_samples_split': [2, 5],
            'min_samples_leaf': [1, 2]
        }

        rf = RandomForestRegressor(random_state=42, n_jobs=-1)
        grid_search = GridSearchCV(
            rf, param_grid, cv=3,  # cv=3 –∏–∑-–∑–∞ –±–æ–ª—å—à–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–æ–º–±–∏–Ω–∞—Ü–∏–π
            scoring='neg_mean_absolute_error',
            n_jobs=-1, verbose=1
        )

        grid_search.fit(self.X_train_scaled, self.y_train)

        print(f"\n‚úÖ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {grid_search.best_params_}")
        print(f"   –õ—É—á—à–∏–π score (MAE): {-grid_search.best_score_:.4f}")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        self.models['random_forest'] = grid_search.best_estimator_

        return self.models['random_forest']

    def evaluate_model(self, model_name, model):
        """–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        print(f"\nüìä –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏: {model_name}")

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        y_pred = model.predict(self.X_test_scaled)

        # –ú–µ—Ç—Ä–∏–∫–∏
        mae = mean_absolute_error(self.y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(self.y_test, y_pred))
        r2 = r2_score(self.y_test, y_pred)

        # –ü—Ä–æ—Ü–µ–Ω—Ç —Ç–æ—á–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π (–≤ –ø—Ä–µ–¥–µ–ª–∞—Ö ¬±0.5)
        tolerance = 0.5
        accurate_predictions = np.abs(self.y_test - y_pred) <= tolerance
        accuracy_percentage = (accurate_predictions.sum() / len(self.y_test)) * 100

        print(f"\n   –ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ:")
        print(f"   ‚Ä¢ MAE (Mean Absolute Error): {mae:.4f}")
        print(f"   ‚Ä¢ RMSE (Root Mean Squared Error): {rmse:.4f}")
        print(f"   ‚Ä¢ R¬≤ (Coefficient of Determination): {r2:.4f}")
        print(f"   ‚Ä¢ –¢–æ—á–Ω–æ—Å—Ç—å (¬±{tolerance}): {accuracy_percentage:.2f}%")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.results[model_name] = {
            'mae': float(mae),
            'rmse': float(rmse),
            'r2': float(r2),
            'accuracy_percentage': float(accuracy_percentage),
            'predictions': y_pred.tolist()
        }

        return mae, rmse, r2, accuracy_percentage

    def compare_models(self):
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π"""
        print("\n" + "="*80)
        print("‚öñÔ∏è –°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô")
        print("="*80)

        # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        comparison_df = pd.DataFrame({
            '–ú–æ–¥–µ–ª—å': list(self.results.keys()),
            'MAE': [self.results[m]['mae'] for m in self.results.keys()],
            'RMSE': [self.results[m]['rmse'] for m in self.results.keys()],
            'R¬≤': [self.results[m]['r2'] for m in self.results.keys()],
            '–¢–æ—á–Ω–æ—Å—Ç—å (¬±0.5)': [self.results[m]['accuracy_percentage'] for m in self.results.keys()]
        })

        print("\nüìä –¢–∞–±–ª–∏—Ü–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:")
        print(comparison_df.to_string(index=False))

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–±–µ–¥–∏—Ç–µ–ª—è
        best_model_name = comparison_df.loc[comparison_df['MAE'].idxmin(), '–ú–æ–¥–µ–ª—å']

        print(f"\nüèÜ –ü–û–ë–ï–î–ò–¢–ï–õ–¨: {best_model_name}")
        print(f"   –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ –º–µ—Ç—Ä–∏–∫–µ MAE")

        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        self.visualize_comparison()

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        best_model = self.models[best_model_name]
        joblib.dump(best_model, 'models/best_model.pkl')
        print(f"\nüíæ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/best_model.pkl")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        comparison_results = {
            'comparison_table': comparison_df.to_dict(orient='records'),
            'best_model': best_model_name,
            'detailed_results': self.results
        }

        with open('data/processed/model_comparison.json', 'w') as f:
            json.dump(comparison_results, f, indent=2)

        print("üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: data/processed/model_comparison.json")

        return best_model_name, comparison_df

    def visualize_comparison(self):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π"""
        print("\nüìä –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π...")

        # –ì—Ä–∞—Ñ–∏–∫ 1: –ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–µ–π
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))

        models = list(self.results.keys())
        mae_values = [self.results[m]['mae'] for m in models]
        rmse_values = [self.results[m]['rmse'] for m in models]
        r2_values = [self.results[m]['r2'] for m in models]
        acc_values = [self.results[m]['accuracy_percentage'] for m in models]

        # MAE
        axes[0, 0].bar(models, mae_values, color=['steelblue', 'coral'])
        axes[0, 0].set_ylabel('MAE')
        axes[0, 0].set_title('Mean Absolute Error (‚Üì –ª—É—á—à–µ)')
        axes[0, 0].grid(True, alpha=0.3, axis='y')

        # RMSE
        axes[0, 1].bar(models, rmse_values, color=['steelblue', 'coral'])
        axes[0, 1].set_ylabel('RMSE')
        axes[0, 1].set_title('Root Mean Squared Error (‚Üì –ª—É—á—à–µ)')
        axes[0, 1].grid(True, alpha=0.3, axis='y')

        # R¬≤
        axes[1, 0].bar(models, r2_values, color=['steelblue', 'coral'])
        axes[1, 0].set_ylabel('R¬≤')
        axes[1, 0].set_title('R¬≤ Score (‚Üë –ª—É—á—à–µ)')
        axes[1, 0].grid(True, alpha=0.3, axis='y')

        # Accuracy
        axes[1, 1].bar(models, acc_values, color=['steelblue', 'coral'])
        axes[1, 1].set_ylabel('–ü—Ä–æ—Ü–µ–Ω—Ç (%)')
        axes[1, 1].set_title('–¢–æ—á–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π (¬±0.5) (‚Üë –ª—É—á—à–µ)')
        axes[1, 1].grid(True, alpha=0.3, axis='y')

        plt.tight_layout()
        plt.savefig('backend/static/graphs/model_comparison_metrics.png', dpi=300, bbox_inches='tight')
        print("   üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: backend/static/graphs/model_comparison_metrics.png")
        plt.close()

        # –ì—Ä–∞—Ñ–∏–∫ 2: –ò—Å—Ç–∏–Ω–Ω—ã–µ vs –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        fig, axes = plt.subplots(1, 2, figsize=(14, 6))

        for idx, (model_name, model) in enumerate(self.models.items()):
            y_pred = model.predict(self.X_test_scaled)

            axes[idx].scatter(self.y_test, y_pred, alpha=0.5, s=20, edgecolors='black', linewidth=0.5)
            axes[idx].plot([self.y_test.min(), self.y_test.max()],
                           [self.y_test.min(), self.y_test.max()],
                           'r--', linewidth=2, label='–ò–¥–µ–∞–ª—å–Ω–∞—è –ª–∏–Ω–∏—è (y=x)')
            axes[idx].set_xlabel('–ò—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è')
            axes[idx].set_ylabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è')
            axes[idx].set_title(f'{model_name}\nR¬≤={self.results[model_name]["r2"]:.3f}')
            axes[idx].legend()
            axes[idx].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig('backend/static/graphs/predictions_comparison.png', dpi=300, bbox_inches='tight')
        print("   üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: backend/static/graphs/predictions_comparison.png")
        plt.close()

    def run_full_training(self):
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è"""
        print("\n" + "="*80)
        print("üöÄ –ó–ê–ü–£–°–ö –û–ë–£–ß–ï–ù–ò–Ø –ú–û–î–ï–õ–ï–ô")
        print("="*80)

        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        self.load_data()

        # 2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        self.prepare_features()

        # 3. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
        self.train_linear_model()
        self.train_ensemble_model()

        # 4. –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π
        print("\n" + "="*80)
        print("üìä –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ï–ô –ù–ê –¢–ï–°–¢–û–í–û–ô –í–´–ë–û–†–ö–ï")
        print("="*80)

        for model_name, model in self.models.items():
            self.evaluate_model(model_name, model)

        # 5. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
        self.compare_models()

        print("\n" + "="*80)
        print("‚úÖ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–ï–®–ù–û!")
        print("="*80)
        print("\nüìÅ –°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
        print("   ‚Ä¢ models/best_model.pkl - –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å")
        print("   ‚Ä¢ models/scaler.pkl - –°–∫–µ–π–ª–µ—Ä")
        print("   ‚Ä¢ models/encoders.pkl - –≠–Ω–∫–æ–¥–µ—Ä—ã")
        print("   ‚Ä¢ data/processed/model_comparison.json - –†–µ–∑—É–ª—å—Ç–∞—Ç—ã")
        print("   ‚Ä¢ backend/static/graphs/*.png - –ì—Ä–∞—Ñ–∏–∫–∏")


if __name__ == "__main__":
    trainer = BoardGameModelTrainer()
    trainer.run_full_training()